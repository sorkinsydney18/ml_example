---
title: "Machine Learning Day 2"
author: "David Kane"
date: "11/20/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(fs)
library(tidymodels)
library(yardstick)
library(tidyverse)

```

## Predicting Democratic Votes


```{r download, cache=TRUE}
# Mostly the same code as Tuesday, but cleaned up. Do you understand what every
# line does? If not, ask your partner!

download.file(url = "https://github.com/TheUpshot/2018-live-poll-results/archive/master.zip",
              destfile = "master.zip",
              quiet = TRUE,
              mode = "wb")

unzip("master.zip")

raw_data <- fs::dir_ls("2018-live-poll-results-master/data") %>%
  map_dfr(read_csv, 
          .id = "source", 
          col_types = cols(.default = col_character(),
                           turnout_scale = col_double(),
                           turnout_score = col_double(),
                           w_LV = col_double(),
                           w_RV = col_double(),
                           final_weight = col_double(),
                           timestamp = col_datetime(format = "")
                            ))

file_delete(c("master.zip", "2018-live-poll-results-master"))

```

```{r clean}
# Data is somewhat messy. Some of our functions require that the dependent
# variable be a factor with two levels, rather than a simple 0/1 variable. Many
# of the variables in the original data are missing for thousands of
# observations. I think it is useful to know the state in which the poll was
# conducted and the office for which the candidates are running.

clean <- raw_data %>% 
  mutate(dvote = as.factor(ifelse(response == "Dem", "Yes", "No"))) %>% 
  mutate(gender = ifelse(gender == "Female", "Female", "Male")) %>% 
  
  mutate(party = case_when(partyid %in% c("Democrat", "Republican") ~ partyid,
                           partyid == "Independent (No party)" ~ "Independent",
                           TRUE ~ "Other")) %>% 
  mutate(state = toupper(str_sub(source, 51, 52))) %>% 
  mutate(office = case_when(str_detect(source, pattern = "sen") ~ "SEN",
                            str_detect(source, pattern = "gov") ~ "GOV",
                            TRUE ~ "HSE")) %>% 
  
  # Might add some other variables later, especially age, education, source.
  
  select(dvote, gender, party, state, office)

```

```{r make_a_model}
# Make a model and then add predictions from that model back to the original
# data. We need the predictions and the original data together so that we can
# evaluate how well our model does. We create two sorts of predictions: the raw
# probability, which is just on a 0--1 scale and the pred_dvote with is a two
# level factor variable just like the original dvote.

# All of this is relatively simple because there is only one independent
# variable in the model and the dependent variable only has two levels.

#remember can't interpret coefficents same as liniear regression - for logistic regression divide by 4 to get roughly same effect as linear 
model_1 <- glm(data = clean, dvote ~ gender, family = "binomial")

x_1 <- clean %>% 
  mutate(prediction = predict(model_1, type = "response")) %>% 
  mutate(pred_dvote = as.factor(ifelse(prediction > mean(prediction), "Yes", "No")))

#how well did our model perform?
x_1 %>% 
  metrics(truth = dvote, estimate = pred_dvote)

#accuracy = proportion of how many your model got correct to total observations
#kap = accounts for things you got right by random chance, 0 being completely by chance, 1 being in completely explained by model 

```

```{r}

model_2 <- glm(data = clean, dvote ~ gender + party + state + office, family = "binomial")

x_2 <- clean %>% 
  mutate(prediction = predict(model_2, type = "response")) %>% 
  mutate(pred_dvote = as.factor(ifelse(prediction > mean(prediction), "Yes", "No")))

metrics(data = x_2, truth = dvote, estimate = pred_dvote)

```



